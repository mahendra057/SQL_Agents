{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Agents, Tools, and LLMs\n\n## **Agents**\nThe core idea of agents is to use a language model to choose a sequence of actions to take.  \nIn **chains**, a sequence of actions is hardcoded (in code).  \nIn **agents**, a language model is used as a reasoning engine to determine which actions to take and in which order.\n\n---\n\n## **1. Large Language Models (LLMs):**\n- **What?**  \n  LLMs (like GPT) are advanced AI models trained to understand and generate human-like text.\n\n- **Role:**  \n  They form the \"brain\" that processes input and generates a response.\n\n- **Example:**  \n  You ask, *\"What's the weather like in Mumbai?\"*, and an LLM generates the text response.\n\n---\n\n## **2. Tools:**\n- **What?**  \n  Tools are additional functionalities or software that help the LLM perform specific tasks it can't handle on its own.\n\n- **Role:**  \n  They enhance the LLM's abilities by providing access to external systems or knowledge.\n\n- **Example:**  \n  - **Calculator Tool:** For solving complex math.  \n  - **Browser Tool:** For fetching real-time information like the latest news.  \n  - **Python Tool:** For running code or analyzing data.\n\n---\n\n## **3. Agents:**\n- **What?**  \n  Agents are decision-makers that combine LLMs and Tools to achieve a goal.\n\n- **Role:**  \n  They think, plan, and use tools (if needed) to complete a task.\n\n- **Example:**  \n  You ask, *\"Find the most affordable flights to Goa this week,\"* and an agent:  \n  - Uses the LLM to understand your request.  \n  - Uses a **browser tool** to search for flight options.  \n  - Combines the results and generates a helpful response.\n","metadata":{}},{"cell_type":"code","source":"!pip install pymysql --upgrade -q\n!pip install google-search-results -q\n!pip install langchain\n!pip install --upgrade langchain_community\n!pip install text-generation\n!pip install langchain-huggingface --upgrade\n!pip install langchain-ollama\n!pip install gradio\n!pip install langchain-google-genai\n!pip install --upgrade --quiet langgraph","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# working on\n#!pip install ipywidgets\n\nfrom huggingface_hub import notebook_login\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"Enter you Huggingface token here\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.agent_toolkits import load_tools\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain.agents import initialize_agent, AgentType, load_tools\n\n# Set the SerpAPI key as an environment variable\nos.environ[\"SERPAPI_API_KEY\"] = \"508fc170cec3408d42ca1e253a9d1a3f840\"\n\n# HuggingFace endpoint configuration\n#ENDPOINT_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B\"\n#llm = HuggingFaceEndpoint(endpoint_url=ENDPOINT_URL, task=\"text-generation\")\n\n# Set the environment variable\nos.environ[\"GOOGLE_API_KEY\"] = \"AIza5mKKfQjnXFQU\"\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n\n\n# Load tools: SerpAPI (for search) and llm-math (for calculations)\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n\n# Initialize the agent with tools\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Recommended for handling multiple tools\n    verbose=True\n)\n\n# Query with search + math\nagent.run(\"Who is ms dhoni? What is her current age raised to the power of 3 ?\")\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SQL Database setup through aws rds, aws benchwork\n\n","metadata":{}},{"cell_type":"markdown","source":"# Steps to Create a MySQL Instance in AWS RDS\n\n### 1. **Log in to AWS**\n- Go to the [AWS Management Console](https://aws.amazon.com/console/).\n\n---\n\n### 2. **Navigate to RDS**\n- In the AWS Console, search for **RDS** in the search bar and click on it.\n\n---\n\n### 3. **Create a Database**\n1. Click on **Create database**.\n2. Under **Database creation method**, select **Standard Create**.\n3. Choose **MySQL** under **Engine Options**.\n4. For **Engine version**, select the latest MySQL version (default is fine).\n\n---\n\n### 4. **Configure Database Details**\n1. **DB Instance Identifier**: Enter `database-1`.\n2. **Master Username**: Enter `admin`.\n3. **Master Password**: Enter `admin123`.\n4. **Confirm Password**: Re-enter `admin123`.\n\n---\n\n### 5. **Select Instance Size**\n1. In the **Instance configuration** section:\n   - Choose **Burstable classes (e.g., db.t3.micro)** for free tier or smaller workloads.\n2. Leave default storage settings unless you want to modify.\n\n---\n\n### 6. **Set Connectivity Options**\n1. **Virtual Private Cloud (VPC)**: Use the default VPC.\n2. **Public Access**: Set **Yes** to allow public access.\n3. **VPC Security Group**: Choose **Create new security group**.\n4. **Inbound Rules**: \n   - Allow traffic from **Anywhere** by setting **0.0.0.0/0** for the port.\n   - Ensure the port is **3306** (default MySQL port).\n\n---\n\n### 7. **Database Name**\n1. Under **Additional Configuration**, set the **Initial Database Name** to `yt_demo`.\n\n---\n\n### 8. **Review and Launch**\n1. Click **Create Database**.\n2. Wait for the status to change to **Available** (this can take a few minutes).\n\n---\n\n### 9. **Access Your Database**\n1. Note down the **Endpoint** from the RDS Dashboard (e.g., `database-1.xxxxxxx.us-east-1.rds.amazonaws.com`).\n2. Use a MySQL client or workbench to connect:\n   ```bash\n   mysql -h database-1.xxxxxxx.us-east-1.rds.amazonaws.com -u admin -p\n   ```\n\n---\n\n### 10. **Test the Connection**\n1. Once connected, create a table or run the following command to test:\n   ```sql\n   SHOW DATABASES;\n   ```\n\nYour MySQL instance is now set up and publicly accessible. Make sure to secure it properly in production environments!\n\n\n\n\n\n\n# Risks and Mitigations in LLM-Based Text-to-SQL Solutions\n\n## 1. **Operational Risk**\n- **Risk**: LLMs may disrupt system operations or data integrity (e.g., deleting files/tables).\n- **Mitigation**: Restrict service account credentials to prevent table deletions.\n\n## 2. **Data Privacy Risk**\n- **Risk**: LLMs may access or disclose sensitive information, violating data privacy regulations like GDPR.\n- **Mitigation**: \n  - Control the information LLMs can access.\n  - Avoid feeding query results back to LLMs unnecessarily.\n  - Sanitize data to remove Personal Identifiable Information (PII).\n\n## 3. **Security Risk**\n- **Risk**: LLMs may gain unauthorized access to databases, compromising security.\n- **Mitigation**: \n  - Use sandboxing to restrict LLM access to specific tables/datasets.\n\n## 4. **Financial Risk**\n- **Risk**: Inefficient queries by LLMs may result in high costs in pay-as-you-go models (e.g., Google BigQuery).\n- **Mitigation**:\n  - Set spending limits using Google Cloud quotas.\n  - Execute \"dry runs\" to estimate query costs before execution.\n\n## Best Practices\n- Assemble components pragmatically using tools like LangChain Expression Language.\n- Implement safety measures to manage risks effectively when building LLM-based solutions.\n","metadata":{}},{"cell_type":"code","source":"!pip install mysql-connector-python\n!pip install  langchain pymysql --upgrade -q","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom langchain.agents import *\nfrom langchain.sql_database import SQLDatabase\nfrom sqlalchemy import create_engine, MetaData","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Aws rds \n# database-1 : DB instance identifier\n# admin : user name\n# admin123 : password\n# yt_demo : database name\n\ndb_user = \"a\"\ndb_password = \"a123\"\ndb_host = \"data-1.rds.amazonaws.com\"\ndb_name = \"classicmodels\"\ndb = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(db.table_info)\nprint(db.dialect)\nprint(db.get_usable_table_names())","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Printing Table names present in Database","metadata":{}},{"cell_type":"code","source":"print(db.get_usable_table_names())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the engine\nengine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n\n# Initialize MetaData\nmetadata = MetaData()\n\n# Reflect the database schema\nmetadata.reflect(bind=engine)\n\ndef get_db_schema():\n    schema_info = \"Database Schema:\\n\"\n    \n    # Loop through all tables\n    for table_name, table in metadata.tables.items():\n        schema_info += f\"\\nTable: {table_name}\\n\"\n        \n        # Loop through columns of the table\n        for column in table.columns:\n            column_name = column.name\n            column_type = column.type\n            max_length = getattr(column.type, 'length', None)\n            schema_info += f\"  Column: {column_name}, Type: {column_type}, Max Length: {max_length}\\n\"\n    \n    return schema_info\n\n# Fetch and print the schema information\nschema_info = get_db_schema()\nprint(schema_info)","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SQL Agents\n\nArchitecture\nAt a high-level, the steps of these systems are:\n\n- Convert question to SQL query: Model converts user input to a SQL query.\n- Execute SQL query: Execute the query.\n- Answer the question: Model responds to user input using the query results.","metadata":{}},{"cell_type":"code","source":"from langchain_community.llms import HuggingFaceTextGenInference\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\n\n# Set environment variables if not already set\nos.environ['LLAMA_meta_3.2_URL'] = \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B\"\n\n#os.environ['HF_TOKEN'] = \"hf_EBCdBlrYVoJxmwFYhHVAqGyPjmutH\"\n\nllm = HuggingFaceTextGenInference(\n    inference_server_url=os.environ['LLAMA_meta_3.2_URL']\n)\n\nchat_model = ChatHuggingFace(llm=llm,  model_id='meta-llama/Llama-3.2-3B')","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\nimport getpass\nimport os\n\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n    \"Enter your Hugging Face API key: \"\n)\n\nENDPOINT_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B\"\n\nllm = HuggingFaceEndpoint(\n    endpoint_url=ENDPOINT_URL,\n    task=\"text-generation\"\n)\nchat_model = ChatHuggingFace(llm=llm,  model_id='meta-llama/Llama-3.2-3B')","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\nimport getpass\nimport os\n\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n    \"Enter your Hugging Face API key: \"\n)\n\nENDPOINT_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-large\"\n\nllm = HuggingFaceEndpoint(\n    endpoint_url=ENDPOINT_URL,\n    task=\"text-generation\",\n    max_new_tokens= 250,\n    stream=False\n)\nchat_model = ChatHuggingFace(llm=llm,  model_id='google/flan-t5-large')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#mistralai/Mixtral-8x7B-Instruct-v0.1\n\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\nimport getpass\nimport os\n\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n    \"Enter your Hugging Face API key: \"\n)\n\nENDPOINT_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n\nllm = HuggingFaceEndpoint(\n    endpoint_url=ENDPOINT_URL,\n    task=\"text-generation\",\n    #max_new_tokens= 250,\n    #stream=False\n)\nchat_model = ChatHuggingFace(llm=llm,  model_id='mistralai/Mixtral-8x7B-Instruct-v0.1')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Set up the LLM, toolkit, and agent executor:","metadata":{}},{"cell_type":"code","source":"#from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits import create_sql_agent\n\n#toolkit = SQLDatabaseToolkit(db=db,llm=llm)\n\nagent_executor = create_sql_agent(\n    llm=llm,\n    db=db,\n    #toolkit=toolkit,\n    verbose=True,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    max_iterations=25,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Query the database with natural language:","metadata":{}},{"cell_type":"code","source":"agent_executor.invoke( \n    {\"input\":\"Describe the orders related table and how they are related\"}\n)","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_executor.invoke(\n    {\n        \"input\": \"List the total no of payments\"\n    }\n)","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_executor.invoke(\n    {\"input\":\"Find the top 5 products with the highest total sales revenue\"}\n)","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating customize database ","metadata":{}},{"cell_type":"code","source":"from langchain.callbacks import get_openai_callback\n\ndef count_tokens(agent, query):\n    with get_openai_callback() as cb:\n        result = agent(query)\n        print(f'Spent a total of {cb.total_tokens} tokens')\n\n    return result\n\nfrom sqlalchemy import MetaData\n\nmetadata_obj = MetaData()\n\n\nfrom sqlalchemy import Column, Integer, String, Table, Date, Float\n\nstocks = Table(\n    \"stocks\",\n    metadata_obj,\n    Column(\"obs_id\", Integer, primary_key=True),\n    Column(\"stock_ticker\", String(4), nullable=False),\n    Column(\"price\", Float, nullable=False),\n    Column(\"date\", Date, nullable=False),\n)\n\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"sqlite:///:memory:\")\nmetadata_obj.create_all(engine)\n\n\nfrom datetime import datetime\n\nobservations = [\n    [1, 'ABC', 200, datetime(2023, 1, 1)],\n    [2, 'ABC', 208, datetime(2023, 1, 2)],\n    [3, 'ABC', 232, datetime(2023, 1, 3)],\n    [4, 'ABC', 225, datetime(2023, 1, 4)],\n    [5, 'ABC', 226, datetime(2023, 1, 5)],\n    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n]\n\nfrom sqlalchemy import insert\n\ndef insert_obs(obs):\n    stmt = insert(stocks).values(\n    obs_id=obs[0],\n    stock_ticker=obs[1],\n    price=obs[2],\n    date=obs[3]\n    )\n\n    with engine.begin() as conn:\n        conn.execute(stmt)\n        \n        \nfor obs in observations:\n    insert_obs(obs)\n    \n    \n!pip install langchain_experimental -qU\n\n\nfrom langchain.utilities import SQLDatabase\nfrom langchain_experimental.sql import SQLDatabaseChain\n\ndb = SQLDatabase(engine)\nsql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n\nfrom langchain.agents import create_sql_agent\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\nfrom langchain.agents.agent_types import AgentType\n\nagent_executor = create_sql_agent(\n    llm=llm,\n    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n    verbose=True,\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    max_iterations=10,\n    handle_parsing_errors=True  # Enable parsing error handling\n)\n\nresult = count_tokens(\n    agent_executor.invoke({\n        \"input\": \"What is the multiplication of the ratio between stock\"\n    })\n)\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# End-to-End Custom SQL Agent with Dynamic Fuse Prompting and Persistent Memory\n\n## Steps for Implementation\n\n1. **LangSmith Configuration**  \n   - Use LangSmith to monitor and understand intermediate steps in the SQL agent process.\n\n2. **Import Llama 3.1**  \n   - Use the open-source Llama 3.1 Instruct version (FP16 4-bit) to run seamlessly on a local system.\n\n3. **Import the Custome Database**  \n   - Utilize the mysql sample database containing multiple tables for SQL operations.\n\n4. **Implement Dynamic Fuse Prompting**  \n   - Use LangChain to create dynamic prompts that enhance the SQL agent's effectiveness.\n\n5. **Create Custom Tools**  \n   - Develop custom tools to assist the SQL agent in performing complex tasks.\n\n6. **SQL Agent Executor**  \n   - Build an SQL agent executor using a React-based agent to process queries.\n\n7. **Persistent Memory Management**  \n   - Incorporate local SQLite to manage multi-session chat histories persistently.\n\n","metadata":{}},{"cell_type":"markdown","source":"### Langsmith Configuration","metadata":{}},{"cell_type":"code","source":"!pip install -U langsmith","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.environ[\"LANGSMITH_API_KEY\"]=\"lsv2_p37f71d3e_614eccb352\"\nlangsmith_api_key = os.environ.get(\"LANGSMITH_API_KEY\")\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"   # we need to set as true by setting this this will save all these logs whatever we are going to see in our llm application into this Langs Smith platform\nos.environ[\"LANGCHAIN_PROJECT\"] = \"SQL Agent\"  # so this one is basically the name of project that we are going to save as in our langsmith platform\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\nos.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key  # this is langsmith api key ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LLM ","metadata":{}},{"cell_type":"code","source":"from langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\n\nENDPOINT_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B\"\n\nllm = HuggingFaceEndpoint(\n    endpoint_url=ENDPOINT_URL,\n    task=\"text-generation\"\n)\nchat_model = ChatHuggingFace(llm=llm,  model_id='meta-llama/Llama-3.2-3B')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#mistralai/Mixtral-8x7B-Instruct-v0.1\n\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\nimport getpass\nimport os\n\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n    \"Enter your Hugging Face API key: \"\n)\n\nENDPOINT_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n\nllm = HuggingFaceEndpoint(\n    endpoint_url=ENDPOINT_URL,\n    task=\"text-generation\",\n    #max_new_tokens= 250,\n    #stream=False\n    max_iterations=25,\n)\nchat_model = ChatHuggingFace(llm=llm,  model_id='mistralai/Mixtral-8x7B-Instruct-v0.1')","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# this llm working fine on sql_chatbot\nimport os\n\n# Set the environment variable\nos.environ[\"GOOGLE_API_KEY\"] = \"AIEm5mKKfQjnXFQU\"\n\n# Access it later in your code\nprint(os.getenv(\"GOOGLE_API_KEY\"))\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\nllm.invoke(\"Explain me Linear regression\")","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Few-Shot Examples\n\nDynamic few-shot prompting can be utilized in this custom SQL agent. It offers two major benefits:\n\n1. **Better Query Understanding**  \n   - By providing examples related to the user's query, the LLM gains a deeper understanding of the intent behind the query.\n\n2. **Cost Efficiency**  \n   - Saves costs by reducing the number of tokens sent to the LLM during processing.\n\n","metadata":{}},{"cell_type":"code","source":"examples = [\n    {   \"input\": \"List all customers.\", \n        \"query\": \"SELECT * FROM customers;\"},\n    {\n        \"input\": \"Find all orders for customer '103'.\",\n        \"query\": \"SELECT * FROM orders WHERE customerNumber = 103;\",\n    },\n    {\n        \"input\": \"List all products in the 'Motorcycles' category.\",\n        \"query\": \"SELECT * FROM products WHERE productLine = 'Motorcycles';\",\n    },\n    {\n        \"input\": \"Find the total sales amount for order number '10100'.\",\n        \"query\": \"SELECT SUM(priceEach * quantityOrdered) FROM orderdetails WHERE orderNumber = 10100;\",\n    },\n    {\n        \"input\": \"List all employees in the 'Sales' department.\",\n        \"query\": \"SELECT * FROM employees WHERE jobTitle = 'VP Sales';\",\n    },\n    {\n        \"input\": \"How many orders are there for customer number '103'?\",\n        \"query\": \"SELECT COUNT(*) FROM orders WHERE customerNumber = 103;\",\n    },\n    {\n        \"input\": \"Find the total number of products in stock.\",\n        \"query\": \"SELECT SUM(quantityInStock) FROM products;\",\n    },\n    {\n        \"input\": \"List all offices in the 'USA'.\",\n        \"query\": \"SELECT * FROM offices WHERE country = 'USA';\",\n    },\n    {\n        \"input\": \"Find the total credit limit for all customers in 'France'.\",\n        \"query\": \"SELECT SUM(creditLimit) FROM customers WHERE country = 'France';\",\n    },\n    {\n        \"input\": \"How many payments have been made by customer number '103'?\",\n        \"query\": \"SELECT COUNT(*) FROM payments WHERE customerNumber = 103;\",\n    },\n]\n\nprint(len(examples))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### How the Agent Works\n\nHere’s the step-by-step approach to build the agent:\n\n1. **Natural Language to SQL Conversion**  \n  - The agent takes user queries in natural language format and converts them into SQL queries.\n  \n\n2. **Fetch Data from Database**  \n - Executes the SQL query to retrieve the required data from the database.\n \n\n3. **Summarized Results**  \n  - Summarizes the fetched data and returns concise results to the user.\n   \n\n4. **Using Few-Shot Examples with Embeddings**  \n   -- **Step 1: Embed Few-Shot Examples**  \n   -  We start by converting 10 predefined example queries into embedding format using an open-source embedding model.\n     \n   -- **Step 2: User Query Embedding**  \n   - At runtime, the user’s query is also converted into embedding format using the same embedding model.\n     \n\n5. **Similarity Search for Relevant Examples**  \n   - A similarity search algorithm identifies the top-K most relevant examples from the predefined set of 10 examples based on the user query.\n\n6. **Enhanced Prompting**  \n   - The selected K examples are appended to the prompt provided to the LLM.  \n   - This ensures the LLM has better context and understanding of the user’s query.\n\n### Benefits of This Approach\n- **Improved Query Understanding**  \n   - The few-shot examples help the LLM interpret user queries more accurately.\n   \n- **Cost Efficiency**  \n   - Fewer tokens are required in the prompt, reducing overall costs.","metadata":{}},{"cell_type":"markdown","source":"#### Dynamic Example Selector","metadata":{}},{"cell_type":"code","source":"from langchain_huggingface import HuggingFaceEmbeddings\nembeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.vectorstores import FAISS\nfrom langchain_core.example_selectors import SemanticSimilarityExampleSelector\n\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    examples,\n    embeddings,\n    FAISS,\n    k=2,\n    input_keys=[\"input\"],\n    )\n\nexample_selector.vectorstore.search(\"List the total no of payments ?\", search_type = \"mmr\")","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating Prompt ","metadata":{}},{"cell_type":"code","source":"system_prefix = \"\"\"You are an agent designed to interact with a SQL database.\nGiven an input question, create a syntactically correct MSSQLServer query to run, then look at the results of the query and return the answer.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\nYou have access to tools for interacting with the database.\nOnly use the given tools. Only use the information returned by the tools to construct your final answer.\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\nYOU MUST provide actionable insights or recommendations after along with the answer.\nYOU MUST identify potential areas for improvement, inefficiencies, or high-performing segments.\nYour insights/recommendations MUST be concise and short.\n\n\n\nYou have access to the following tools for interacting with the database:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of {tool_names}\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\n-- TABLE SCHEMA WITH DESCRIPTION --\n\nThis is schema_info and respected data types of each table columns\n{schema_info}\n\n\n\n Customers Table:\n customerNumber: Unique identifier for each customer.\n customerName: The name of the customer or company.\n contactLastName / contactFirstName: Contact person’s name for the customer.\n phone / addressLine1 / addressLine2 / city / state / postalCode / country: Customer contact and location details.\n salesRepEmployeeNumber: Links to the employee managing the customer account.\n creditLimit: The credit limit assigned to the customer.\n\n Employees Table:\n employeeNumber: Unique identifier for each employee.\n lastName / firstName: Employee's name.\n extension / email: Contact details of the employee.\n officeCode: Links to the office where the employee is based.\n reportsTo: Employee’s manager.\n jobTitle: Role of the employee in the organization.\n\n Offices Table:\n officeCode: Unique identifier for each office.\n city / state / country / addressLine1 / addressLine2 / postalCode: Location details of the office.\n phone / territory: Contact information and territory covered by the office.\n\n Order Details Table:\n orderNumber: Links to the orders table for specific orders.\n productCode: Links to the products table for details about ordered products.\n quantityOrdered: Quantity of the product ordered.\n priceEach: Price of each unit in the order.\n orderLineNumber: Line item number within the order.\n\n Orders Table:\n orderNumber: Unique identifier for each order.\n orderDate / requiredDate / shippedDate: Key dates in the order lifecycle.\n status: Current status of the order (e.g., Shipped, Cancelled).\n comments: Additional information about the order.\n customerNumber: Links to the customer placing the order.\n\n Products Table:\n productCode: Unique identifier for each product.\n productName / productLine / productScale / productVendor: Key details about the product.\n productDescription: Description of the product.\n quantityInStock: Current inventory for the product.\n buyPrice / MSRP: Cost and Manufacturer's Suggested Retail Price of the product.\n\n Product Lines Table:\n productLine: Unique identifier for each product category.\n textDescription / htmlDescription / image: Detailed information and visuals of the product line.\n\n Payments Table:\n customerNumber: Links to the customer making the payment.\n checkNumber: Unique identifier for the payment.\n paymentDate: Date the payment was made.\n amount: Payment amount.\n\n Key Relationships:\n Customer to Orders: customerNumber links the Customers table to Orders.\n Orders to Order Details: orderNumber links the Orders table to Order Details.\n Order Details to Products: productCode links the Order Details table to Products.\n Products to Product Lines: productLine links the Products table to Product Lines.\n Customer to Payments: customerNumber links the Customers table to Payments.\n Employee to Customers: salesRepEmployeeNumber in Customers links to employeeNumber in Employees.\n Employee to Offices: officeCode links the Employees table to Offices.\n\n# Objective:\n# The business team will ask natural language questions to derive insights related to customer management, product sales, order processing, and payment trends. \n# This structured data should be used to analyze performance, customer engagement, and operational efficiency.\n\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n\n\nIf the question does not seem related to the database, just return \"I don't know\" as the answer.\nDON'T MAKE UP AN ANSWER, IT IS ILLEGAL TO DO SO.\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n\ndynamic_few_shot_prompt = FewShotPromptTemplate(\n    example_selector = example_selector,\n    example_prompt=PromptTemplate.from_template(\n        \"User input: {input}\\nSQL query: {query}\"\n    ),\n    input_variables=[\"input\",\"tools\",\"tool_names\",\"db_schema\"],\n    prefix=system_prefix,\n    suffix=\"\"\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.prompts import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    MessagesPlaceholder,\n)\n\nfull_prompt = ChatPromptTemplate.from_messages(\n    [\n        SystemMessagePromptTemplate(prompt=dynamic_few_shot_prompt),\n        (\"human\", \"{input}\"),\n        MessagesPlaceholder(variable_name='agent_scratchpad'),\n    ]\n)\n\nprint(full_prompt)\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool, InfoSQLDatabaseTool, ListSQLDatabaseTool, QuerySQLCheckerTool\n\n# tools in the tools list are part of a toolkit designed for interacting with a SQL database through an AI agent. Each tool serves a specific purpose, enabling the agent to work with the database effectively\n\ntools = [\n    QuerySQLDataBaseTool(db=db),  # Executes SQL queries on the database. What it does: When the agent generates a SQL query (like \"Get all customers who made a purchase last month\"), this tool runs the query on the database and retrieves the results.\n    InfoSQLDatabaseTool(db=db),  # Retrieves information about the database structure. What it does: It tells the agent details about the database, like the names of tables, the columns in each table, and their data types.\n    ListSQLDatabaseTool(db=db), # Lists all available tables in the database. What it does: This tool helps the agent see what data is stored in the database by providing the names of all the tables.\n    QuerySQLCheckerTool(db=db, llm=llm)  #  Validates SQL queries before running them. What it does: Checks if the SQL query written by the agent is syntactically correct and valid for the database.\n]\n\ntool_names = [tool.name for tool in tools]\ntool_descriptions = [tool.name + \" - \" + tool.description.strip() for tool in tools]\n\n# How the full prompt looks like when we pass to the llm model by the below codeInclude schema_info in the second invocation\nprompt_val = full_prompt.invoke(\n    {\n        \"input\": \"List the total no of payments?\",\n        \"tool_names\": tool_names,\n        \"tools\": tool_descriptions,\n        \"schema_info\": schema_info,\n        \"agent_scratchpad\": []\n    }\n)\n\nprint(prompt_val.to_string())\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits import create_sql_agent\n\n\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)  # It's a pre-configured collection of tools bundled together to allow an AI agent to interact seamlessly with a SQL database. Components: Internally, it integrates tools like QuerySQLDataBaseTool, InfoSQLDatabaseTool, ListSQLDatabaseTool, and QuerySQLCheckerTool, and ensures they work in harmony.\n\nagent_executor = create_sql_agent(\n    llm=llm,\n    toolkit=toolkit,\n    prompt=full_prompt,\n    #verbose=True,\n    agent_type=\"tool-calling\"  # This agent type is designed specifically for scenarios where the agent interacts with external tools, APIs, or systems to gather information or perform actions before formulating a response.\n    \n)\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_executor.invoke( \n    {\n        \"input\":\"Find the names and phone numbers of all customers.\",\n        \"tool_names\": tool_names,\n        \"tools\": tools,\n        \"schema_info\":schema_info,\n        \"agent_scratchpad\": []\n    }\n)\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr\nimport uuid\nfrom langchain_community.chat_message_histories import SQLChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\n\nlast_k_messages = 4\n\n# Function to handle session history\ndef get_session_history(session_id):\n    chat_message_history = SQLChatMessageHistory(\n        session_id=session_id, connection=\"sqlite:///memory.db\", table_name=\"local_table\"\n    )\n    messages = chat_message_history.get_messages()\n    chat_message_history.clear()\n    \n    for message in messages[-last_k_messages:]:\n        chat_message_history.add_message(message)\n    \n    return chat_message_history\n\n# Initialize RunnableWithMessageHistory\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    get_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)\n\n# Function to handle user messages and generate responses\ndef respond(message, chatbot_history, session_id):\n    if not chatbot_history:\n        session_id = uuid.uuid4().hex\n\n    print(\"Session ID: \", session_id)\n\n    # Invoke the agent with the provided message and session context\n    response = agent_with_chat_history.invoke(\n        {\n            \"input\": message,\n            \"tool_names\": tool_names,  # Pass tool names\n            \"tools\": tool_descriptions,  # Pass tool descriptions\n            \"schema_info\": schema_info,\n        },\n        {\"configurable\": {\"session_id\": session_id}},\n    )\n\n    # Extract only the Final Answer from the response\n    full_output = response.get(\"output\", \"No final answer found.\")  # Ensure this matches your agent's response structure\n    final_answer = None\n\n    if \"Final Answer:\" in full_output:\n        final_answer = full_output.split(\"Final Answer:\")[1].strip()  # Extract text after \"Final Answer:\"\n    else:\n        final_answer = \"Final Answer not found in response.\"\n\n    # Append the message and the final answer to the chatbot history\n    chatbot_history.append((message, final_answer))\n\n    # Return updated state\n    return \"\", chatbot_history, session_id\n\n# Gradio App Definition\nwith gr.Blocks() as demo:\n    # Define UI elements\n    state = gr.State(\"\")  # Maintain session state\n    chatbot = gr.Chatbot()  # Chat interface\n    msg = gr.Textbox(label=\"Your Query\", placeholder=\"Ask your NLP query here...\")  # Input box\n    clear = gr.ClearButton([msg, chatbot])  # Clear button\n\n    # Bind the respond function to the message submit event\n    msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])\n\n# Launch the Gradio App\ndemo.launch()\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# not working on\nlast_k_messages = 4\n\n\nfrom langchain_community.chat_message_histories import SQLChatMessageHistory\n\ndef get_session_history(session_id):\n    chat_message_history = SQLChatMessageHistory(\n    session_id=session_id, connection = \"sqlite:///memory.db\", table_name = \"local_table\"\n    )\n\n    messages = chat_message_history.get_messages()\n    chat_message_history.clear()\n    \n    for message in messages[-last_k_messages:]:\n        chat_message_history.add_message(message)\n    \n    print(\"chat_message_history \", chat_message_history)\n    return chat_message_history\n\n\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\n\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    get_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# not working on\nimport gradio as gr\nimport uuid\n\nwith gr.Blocks() as demo:\n    \n    state = gr.State(\"\")\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chatbot_history, session_id):\n        # Proper indentation begins here\n        if not chatbot_history:\n            session_id = uuid.uuid4().hex\n\n        print(\"Session ID: \", session_id)\n\n        response = agent_with_chat_history.invoke(\n            {\n                \"input\": message,\n                \"tool_names\": tool_names,  # Pass tool names\n                \"tools\": tool_descriptions,  # Pass tool descriptions\n                \"schema_info\":schema_info,\n            },\n            {\"configurable\": {\"session_id\": session_id}},\n        )\n\n        chatbot_history.append((message, response['output']))\n        return \"\", chatbot_history, session_id\n\n    msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])\n\ndemo.launch()\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating table records and other operations manually on created table through aws rds instance","metadata":{}},{"cell_type":"code","source":"import mysql.connector\n\n# Establish a connection to the database\ndef create_connection():\n    connection = mysql.connector.connect(\n        host=\"database-1ast-1.rds.amazonaws.com\",\n        user=\"a\",\n        password=\"a183\",\n        database=\"y\"\n    )\n    return connection","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"connection = create_connection()\nconnection","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a sample table\ndef create_table(connection):\n    cursor = connection.cursor()\n    cursor.execute(\"CREATE TABLE IF NOT EXISTS sample (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255), age INT)\")\n\ncreate_table(connection)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Insert a record\ndef insert_record(connection, name, age):\n    cursor = connection.cursor()\n    query = \"INSERT INTO sample (name, age) VALUES (%s, %s)\"\n    cursor.execute(query, (name, age))\n    connection.commit()\n     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"insert_record(connection, \"John Doe\", 30)\ninsert_record(connection, \"Jane Smith\", 28)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select records\ndef select_records(connection):\n    cursor = connection.cursor()\n    cursor.execute(\"SELECT * FROM sample\")\n    rows = cursor.fetchall()\n    for row in rows:\n        print(row)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"select_records(connection)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Update a record\ndef update_record(connection, name, age, id):\n    cursor = connection.cursor()\n    query = \"UPDATE sample SET name = %s, age = %s WHERE id = %s\"\n    cursor.execute(query, (name, age, id))\n    connection.commit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"update_record(connection, \"John Doe\", 31, 1)\nselect_records(connection)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Delete a record\ndef delete_record(connection, id):\n    cursor = connection.cursor()\n    query = \"DELETE FROM sample WHERE id = %s\"\n    cursor.execute(query, (id,))\n    connection.commit()\ndelete_record(connection, 1)\n     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"select_records(connection)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}